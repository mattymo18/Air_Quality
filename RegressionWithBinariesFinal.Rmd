---
title: "RegressionWithBinaries"
output:
  pdf_document: default
  html_document: default
---
Authors: Akshay Sridharan, Andy Ackerman, Matt Johnson

```{r message=FALSE}
library(tidyverse)
library(lubridate)
library(gplots)
library(glmnet)
library(pscl)
library(dplyr)
library(knitr)
library(kableExtra)
library(broom)
library(leaps)
library(olsrr)
library(memisc)
library(pander)
library(car)
```

```{r message=FALSE}
DF <- read_csv("derived_data/DF.Final.csv")
```

Our final dataframe utilized within the analysis contains 418 total observations, with 198 being data on Raleigh, NC, and 220 being data on Greenville, SC. For Raleigh, NC, we have consecutive observations for the dates from January 10th, 2020 to March 24th, 2020 and additionally from June 1st, 2020 to October 12th, 2020. For Greenville, SC, we have consecutive observations from March 2nd, 2020 to October 12th, 2020.

Initializing function for use in evaluating RMSE
```{r}
rmse=function(x,y){sqrt(mean((x-y)^2))}
```

Initial Panel regression model with non-zero intercept
```{r}
fixed_effect1 <- lm(newcasesper ~ PM25 + O3 + factor(Location) + Stay_At_Home + Bar_Close, DF)
summary(fixed_effect1)
```

Selection methods applied to non-zero intercept model
```{r}
#Create numeric binary variable for location with Raleigh = 1 and Greenville = 0.
DF$loc <- ifelse(DF$Location == "Raleigh", 1, 0)

#Initialize train and test sets. These will be randomized with 75% of observations composing the training set and 25% of the observations composing the test set.

#75% of the sample size
smp_size <- floor(0.75 * nrow(DF))

#Setting a seed for the sake of reproducibility.
set.seed(123)
train_ind <- sample(seq_len(nrow(DF)), size = smp_size)

#Form test and train sets
train <- DF[train_ind,]
test <- DF[-train_ind,]

reglm1 <- regsubsets(newcasesper ~ PM25 + O3 + factor(Location) + Stay_At_Home + Bar_Close, train)
lm1s <- summary(reglm1)
lm1 <- lm(newcasesper ~ PM25 + O3 + factor(Location) + Stay_At_Home + Bar_Close, train)

#AIC
fixed_effect1.1 <- step(lm1)

#Adjusted R^2
lm1s$which[which.max(lm1s$adjr2),]
plot(2:6,lm1s$adjr2,xlab="No. of Parameters",ylab="Adjusted R-square")

#Mallow's Cp
lm1s$which[which.min(lm1s$cp),]
plot(2:6,lm1s$cp,xlab="No. of Parameters",ylab="Cp Statistic")
abline(0,1)

#From the above variable selection methods we see that the model that optimizes
#the Adjusted R^2 metric is the one predicting `newcasesper` by an intercept 
#term and the variables `PM25`, `O3`, `factor(Location)Raleigh`, `Stay_At_Home`,
#and `Bar_Close`. The model that optimizes the AIC and Mallow's Cp
#statistic is the one predicting `newcasesper` by an intercept term and
#the variables `PM25`, `factor(Location)Raleigh`, `Stay_At_Home`, and 
#`Bar_Close`. However, the statistic for this model is slightly above
#the Cp = p line when considering the Mallow's Cp metric. We will 
#thereby proceed by considering both of these models.

fixed_effect_intercept1 <- lm(newcasesper ~ O3 + PM25 + factor(Location) + Stay_At_Home + Bar_Close, train)
fixed_effect_intercept2 <- lm(newcasesper ~ PM25 + factor(Location) + Stay_At_Home + Bar_Close, train)
 
#Calculating the prediction RMSE on the test set
rmse(fitted(fixed_effect_intercept1), train$newcasesper)
rmse(predict(fixed_effect_intercept1,test),test$newcasesper)

rmse(fitted(fixed_effect_intercept2), train$newcasesper)
rmse(predict(fixed_effect_intercept2,test),test$newcasesper)

#Considering the residual Q-Q plot to visualize any violations of the normality assumption.
ols_plot_resid_qq(fixed_effect_intercept1)
ols_plot_resid_qq(fixed_effect_intercept2)

#Examining DFBETA plots to identify points particularly influential in estimating each parameter.
ols_plot_dfbetas(fixed_effect_intercept1)
ols_plot_dfbetas(fixed_effect_intercept2)

#Determining high leverage points using Cook's Distance. Threshold established as 4/(n-k-1),
#where n is the number of observations and k denotes the number of independent variables.
ols_plot_cooksd_bar(fixed_effect_intercept1)
ols_plot_cooksd_bar(fixed_effect_intercept2)

#Identifying Cook's D statistic outliers with threshold 4/(n-k-1)
mod1outliers <- ols_plot_cooksd_bar(fixed_effect_intercept1)$data[ols_plot_cooksd_bar(fixed_effect_intercept1)$data$fct_color == "outlier",]
mod2outliers <- ols_plot_cooksd_bar(fixed_effect_intercept2)$data[ols_plot_cooksd_bar(fixed_effect_intercept2)$data$fct_color == "outlier",]

train[mod1outliers$obs,]
train[mod2outliers$obs,]
train[union(mod1outliers$obs, mod2outliers$obs),]
train[intersect(mod1outliers$obs, mod2outliers$obs),]

train3 <- train
train3$outlier <- ifelse(train3$X1 %in% train[union(mod1outliers$obs,mod2outliers$obs),]$X1,1,0)

#Visualizing outliers
ggplot(train3, aes(y= newcasesper, x = PM25, color = outlier)) + geom_point()
ggplot(train3, aes(y= newcasesper, x = O3, color = outlier)) + geom_point()
ggplot(train3, aes(y= PM25, x = O3, color = outlier)) + geom_point()
ggplot(train3[train3$outlier == 1,], aes(y= PM25, x = Stay_At_Home)) + geom_point()
ggplot(train3[train3$outlier == 1,], aes(y= PM25, x = Bar_Close)) + geom_point()
ggplot(train3[train3$outlier == 1,], aes(y= newcasesper, x = Stay_At_Home)) + geom_point()
ggplot(train3[train3$outlier == 1,], aes(y= newcasesper, x = Bar_Close)) + geom_point()

#Refitting models without outlier observations as sensitivity analysis
train1 <- train[-mod1outliers$obs,]
train2 <- train[-mod2outliers$obs,]

fixed_effect_intercept1.no <- lm(newcasesper ~ O3 + PM25 + factor(Location) + Stay_At_Home + Bar_Close, train1)
fixed_effect_intercept2.no <- lm(newcasesper ~ PM25 + factor(Location) + Stay_At_Home + Bar_Close, train2)

#Model fits without the omission of outliers
summary(fixed_effect_intercept1)
summary(fixed_effect_intercept2)

#Model fits with omission of Cook's D statistic outliers
summary(fixed_effect_intercept1.no)
summary(fixed_effect_intercept2.no)

#Examination of multicollinearity in the model using the variance inflation factor
vif(fixed_effect_intercept1) %>%
  pander(caption = "Variance Inflation Factor values for 5 parameter model")
vif(fixed_effect_intercept2) %>%
  pander(caption = "Variance Inflation Factor values for 4 parameter model")
```

Panel regression models with zero intercept
```{r}
fixed_effect2 <- lm(newcasesper ~ PM25 + O3 + Stay_At_Home + Bar_Close + loc - 1, train)
```

Selection methods applied to zero-intercept model
```{r}
reglm2 <- regsubsets(newcasesper ~ PM25 + O3 + Stay_At_Home + Bar_Close + loc, train, intercept = F)
lm2s <- summary(reglm2)
lm2 <- lm(newcasesper ~ PM25 + O3 + Stay_At_Home + Bar_Close + loc - 1, train)

#AIC
fixed_effect2.1 <- step(lm2)
summary(fixed_effect2.1)

#Adjusted R^2
lm2s$which[which.max(lm2s$adjr2),]
plot(1:5,lm2s$adjr2,xlab="No. of Parameters",ylab="Adjusted R-square")


#Mallow's Cp
lm2s$which[which.min(lm2s$cp), ]
plot(1:5,lm1s$cp,xlab="No. of Parameters",ylab="Cp Statistic")
abline(0,1)

#From the above variable selection methods we see that the zero-intercept
#model that optimizes the Adjusted R^2, AIC, and Mallow's Cp metrics 
#is the one predicting `newcasesper` by the variables `PM25`, 'O3', `loc`,
#`Stay_At_Home`, and `Bar_Close`. In other words, the complete model 
#is the one that optimizes the values of all three variable selection
#methods. We will thereby proceed by considering this model.

fixed_effect_ni <- lm(newcasesper ~ O3 + PM25 + loc + Stay_At_Home + Bar_Close - 1, train)
 
#Calculating the prediction RMSE on the test set
rmse(fitted(fixed_effect_ni), train$newcasesper)
rmse(predict(fixed_effect_ni,test),test$newcasesper)

#Considering the residual Q-Q plot to visualize any violations of the normality assumption.
ols_plot_resid_qq(fixed_effect_ni)

#Examining DFBETA plots to identify points particularly influential in estimating each parameter.
ols_plot_dfbetas(fixed_effect_ni)

#Determining high leverage points using Cook's Distance. 
ols_plot_cooksd_bar(fixed_effect_ni)

#Identifying Cook's D statistic outliers with threshold 4/(n-k-1)
mod3outliers <- ols_plot_cooksd_bar(fixed_effect_ni)$data[ols_plot_cooksd_bar(fixed_effect_ni)$data$fct_color == "outlier",]

train4 <- train[-mod3outliers$obs,]

intersect(mod1outliers$obs,mod3outliers$obs)

fixed_effect_ni.no <- lm(newcasesper ~ O3 + PM25 + loc + Stay_At_Home + Bar_Close - 1, train4)

#Model fit without the omission of outliers
summary(fixed_effect_ni)

#Model fit with omission of Cook's D statistic outliers
summary(fixed_effect_ni.no)


vif(fixed_effect_ni) %>%
  pander(caption = "Variance Inflation Factor values for zero-intercept, 5 parameter model")

cor(train[,c("O3","PM25","loc","Stay_At_Home","Bar_Close")]) %>%
  pander
```

Multicollinearity Discussion:

We next begin consideration of potential issues of multicollinearity within our models. To do so, we compute the variance inflation factors for each of our predictors in each regression. Note that the notion of the variance inflation factor 

Non-zero intercept models:
As shown by the Variance Inflation Factor tables, the computed values are consistently below 2.2, indicating low to moderate multicollinearity per the oft-cited threshold values of 5 and 10.

Zero-intercept model:
As the estimation of the predictor R$^2$ values could potentially be negative given the constraint on the intercept term, the Variance Inflation Factor metrics used in the preceding discussion cannot be directly applied with strong interpretation. However, applying the same calculation methods we still see that the Variance Inflation Factors computed are consistently below the threshold value of 5 indicating moderate multicollinearity. Further inspecting a correlation matrix of the predictors we see that the Pearson correlation between the pairs (`O3`,`Stay_At_Home`), (`Bar_Close`, `loc`), and (`Bar_Close`, `Stay_At_Home`) are particularly large in magnitude and are further all positive. This correlation is logical for the pair (`Bar_Close`, `Stay_At_Home`) and provides insight into the positive coefficient for the `Bar_Close` variable. In the correlation for the pair (`Bar_Close`, `loc`) we see a reflection of the extended duration of bar closures in Raleigh relative to Greenville, and so this once again follows logically. Finally, the positive correlation in the pair (`O3`, `Stay_At_Home`) is of some interest and provides evidence against our guiding hypothesis. With respect to discussion of multicollinearity, however, the values do not provide strong evidence for concern, especially given the Variance Inflation Factors calculated for the same variables in the Non-zero intercept models.


```{r}
rmse(fitted(fixed_effect_intercept1), train$newcasesper)
rmse(predict(fixed_effect_intercept1,test),test$newcasesper)

RMSEm1 <- data.frame(matrix(ncol = 2, nrow = 1))
colnames(RMSEm1) <- c("Training RMSE", "Test RMSE")
RMSEm1[1,1] <- rmse(fitted(fixed_effect_intercept1), train$newcasesper)
RMSEm1[1,2] <- rmse(predict(fixed_effect_intercept1,test),test$newcasesper)

RMSEm1 %>%
  pander(caption = "Fixed-Effects Model with non-zero intercept and 6 parameters")

rmse(fitted(fixed_effect_intercept2), train$newcasesper)
rmse(predict(fixed_effect_intercept2,test),test$newcasesper)

RMSEm2 <- data.frame(matrix(ncol = 2, nrow = 1))
colnames(RMSEm2) <- c("Training RMSE", "Test RMSE")
RMSEm2[1,1] <- rmse(fitted(fixed_effect_intercept2), train$newcasesper)
RMSEm2[1,2] <- rmse(predict(fixed_effect_intercept2,test),test$newcasesper)

RMSEm2 %>%
  pander(caption = "Fixed-Effects Model with non-zero intercept and 5 parameters")

rmse(fitted(fixed_effect_ni), train$newcasesper)
rmse(predict(fixed_effect_ni,test),test$newcasesper)

RMSEm3 <- data.frame(matrix(ncol = 2, nrow = 1))
colnames(RMSEm3) <- c("Training RMSE", "Test RMSE")
RMSEm3[1,1] <- rmse(fitted(fixed_effect_ni), train$newcasesper)
RMSEm3[1,2] <- rmse(predict(fixed_effect_ni,test),test$newcasesper)

RMSEm3 %>%
  pander(caption = "Fixed-Effects Model with zero-intercept and 5 parameters")
```

